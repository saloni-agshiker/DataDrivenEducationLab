{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gensim         #commonly used for NLP processing tasks (like topic modeling)\n",
        "from gensim import corpora, models\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "gOpxNMwKP0aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3BdxKOuPOHtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpQWTcvINl12",
        "outputId": "4cdc0cbe-5b5c-4b16-90b2-b2071bc8bf91",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of docs:  6466\n",
            "                                        cleaned_text  index\n",
            "0  enter answer without space crazy trying kind w...      0\n",
            "1  answer question tried everything nothing seems...      1\n",
            "2  passed output printed bubble line misleading u...      2\n",
            "3  problem question try advise bogus variable ans...      3\n",
            "4  knew bone typo gut feeling submitted without w...      4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ad0681958e5f>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_text['index'] = data_text.index\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('sample_data/abcnews-date-text.csv');\n",
        "data_text = data[['headline_text']]\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text\n",
        "\n",
        "print(\"Number of docs: \", len(documents))\n",
        "print(documents[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = documents['headline_text'].str.split()\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs) #tokenizes each headline (makes each headline into an array with each word as a separate element)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems(): #prints first 10 entries in the dictionary w/ their unique ID\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "kykE4Yl3PzXn",
        "outputId": "fad17b36-4cf3-4c39-ce7d-b30eac86d40f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'documents' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b86cbcf93af2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_docs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tokenizes each headline (makes each headline into an array with each word as a separate element)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#prints first 10 entries in the dictionary w/ their unique ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'documents' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000) #filter tokens that appear in less than 15 docs or more than 50% of the docs"
      ],
      "metadata": {
        "id": "1tOnJ0n6S_cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a bag of words (BoW) representation for each doc in processed_docs using the dictionary\n",
        "# BoW format transforms a document (list of words) into a list of (word_id, frequency) tuples, where frequency is the # of times the word appears in the doc\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310] #prints the BoW representation for document 4310"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Le4lazTUK4",
        "outputId": "8d5d7345-d1c9-49e5-8967-a9d4fa52a39c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(14, 1),\n",
              "  (16, 1),\n",
              "  (138, 1),\n",
              "  (421, 1),\n",
              "  (1152, 1),\n",
              "  (1155, 1),\n",
              "  (2480, 1),\n",
              "  (2500, 1)],\n",
              " [(138, 1), (2766, 1), (2959, 1), (4173, 1)],\n",
              " [(54, 1), (633, 1), (4705, 1), (6593, 1)],\n",
              " [(643, 1), (1634, 1), (6427, 1), (6594, 1)],\n",
              " [(643, 1), (1301, 1), (3720, 1), (6595, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(\n",
        "        bow_doc_4310[i][0],                     # unique ID of word\n",
        "        dictionary[bow_doc_4310[i][0]],         # actual word from dictionary\n",
        "        bow_doc_4310[i][1]))                    # frequency of word in doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02XYyTe7U_-l",
        "outputId": "9183dee9-e986-4110-a797-22d3d7df83a6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 218 (\"govt\") appears 1 time.\n",
            "Word 319 (\"group\") appears 1 time.\n",
            "Word 801 (\"local\") appears 1 time.\n",
            "Word 1922 (\"wants\") appears 1 time.\n",
            "Word 5732 (\"compulsory\") appears 1 time.\n",
            "Word 5733 (\"ratepayers\") appears 1 time.\n",
            "Word 5734 (\"voting\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = models.TfidfModel(bow_corpus) # creates a TF-IDF model from the bow_corpus\n",
        "corpus_tfidf = tfidf[bow_corpus]      # transforms the entire BoW corpus into TF-IDF weighted form\n",
        "for doc in corpus_tfidf:\n",
        "    word_tfidf = [(dictionary[id], score) for id, score in doc]\n",
        "    pprint(word_tfidf)\n",
        "    #pprint(doc) # pretty-prints the first transformed doc, where each tuple consists of (word ID, TF-IDF score)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvt9tK2ZWaGg",
        "outputId": "ba5655e1-eaa9-489a-e524-99b1606d23ab",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('aba', 0.5170653357672524),\n",
            " ('against', 0.2404907204681067),\n",
            " ('broadcasting', 0.5010942074514545),\n",
            " ('community', 0.28032354288321143),\n",
            " ('decides', 0.46172189338729547),\n",
            " ('licence', 0.3632407626457737)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2) # training LDA  with BoW corpus\n",
        "# in this case, common words (eg: \"the\", \"is\") may dominate => problematic"
      ],
      "metadata": {
        "id": "b5lAoI9jYe5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieves topics from the LDA model (-1 as the arg means retrieve all topics)\n",
        "# each topic is a list of words that represents the probabilistic distribution of words within that topic\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic)) # idx is the index/ID of the topic, topic is the list of words associated w/ the topic along with their weights\n",
        "\n",
        "# each line represents 1 topic that the model has learned from the entire corpus & a document will contain a mixture of these topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IT8JQtRbGmD",
        "outputId": "18f9bf4b-59f5-4546-ba86-4e3436545e4a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.093*\"to\" + 0.025*\"for\" + 0.015*\"nt\" + 0.013*\"vaccine\" + 0.011*\"be\" + 0.011*\"live\" + 0.010*\"federal\" + 0.010*\"national\" + 0.010*\"scott\" + 0.009*\"nsw\"\n",
            "Topic: 1 \n",
            "Words: 0.069*\"in\" + 0.043*\"covid\" + 0.036*\"after\" + 0.028*\"19\" + 0.018*\"at\" + 0.014*\"sydney\" + 0.012*\"by\" + 0.011*\"found\" + 0.011*\"fire\" + 0.011*\"crash\"\n",
            "Topic: 2 \n",
            "Words: 0.058*\"coronavirus\" + 0.031*\"in\" + 0.028*\"of\" + 0.021*\"victoria\" + 0.017*\"for\" + 0.017*\"nsw\" + 0.015*\"cases\" + 0.013*\"coast\" + 0.012*\"south\" + 0.012*\"australia\"\n",
            "Topic: 3 \n",
            "Words: 0.045*\"over\" + 0.040*\"of\" + 0.026*\"police\" + 0.024*\"in\" + 0.020*\"man\" + 0.019*\"court\" + 0.013*\"murder\" + 0.012*\"for\" + 0.012*\"who\" + 0.011*\"charged\"\n",
            "Topic: 4 \n",
            "Words: 0.037*\"for\" + 0.033*\"to\" + 0.014*\"health\" + 0.011*\"royal\" + 0.010*\"quarantine\" + 0.009*\"calls\" + 0.009*\"new\" + 0.009*\"workers\" + 0.009*\"school\" + 0.009*\"commission\"\n",
            "Topic: 5 \n",
            "Words: 0.032*\"us\" + 0.027*\"in\" + 0.020*\"trump\" + 0.020*\"with\" + 0.018*\"by\" + 0.017*\"what\" + 0.015*\"china\" + 0.015*\"are\" + 0.013*\"of\" + 0.011*\"as\"\n",
            "Topic: 6 \n",
            "Words: 0.095*\"the\" + 0.030*\"in\" + 0.028*\"to\" + 0.028*\"of\" + 0.015*\"on\" + 0.013*\"for\" + 0.012*\"a\" + 0.012*\"australia\" + 0.012*\"donald\" + 0.012*\"at\"\n",
            "Topic: 7 \n",
            "Words: 0.028*\"to\" + 0.021*\"government\" + 0.018*\"about\" + 0.015*\"on\" + 0.015*\"restrictions\" + 0.014*\"of\" + 0.011*\"water\" + 0.010*\"care\" + 0.010*\"premier\" + 0.010*\"for\"\n",
            "Topic: 8 \n",
            "Words: 0.040*\"queensland\" + 0.028*\"election\" + 0.025*\"how\" + 0.021*\"to\" + 0.020*\"police\" + 0.017*\"for\" + 0.014*\"trial\" + 0.012*\"with\" + 0.011*\"missing\" + 0.011*\"and\"\n",
            "Topic: 9 \n",
            "Words: 0.031*\"to\" + 0.030*\"a\" + 0.029*\"says\" + 0.022*\"is\" + 0.016*\"news\" + 0.015*\"will\" + 0.015*\"and\" + 0.014*\"be\" + 0.013*\"of\" + 0.013*\"not\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4) # training LDA with TF-IDF corpus\n",
        "# common words are downweighted & rare words are emphasized => more accurate\n",
        "\n",
        "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QumBjQwcdmI",
        "outputId": "62c53938-ed98-45f7-b058-081fc01dc45e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.4756768047809601\t \n",
            "Topic: 0.010*\"to\" + 0.008*\"government\" + 0.007*\"for\" + 0.005*\"coronavirus\" + 0.005*\"on\" + 0.005*\"the\" + 0.005*\"restrictions\" + 0.005*\"wednesday\" + 0.005*\"in\" + 0.005*\"of\"\n",
            "\n",
            "Score: 0.28774964809417725\t \n",
            "Topic: 0.009*\"to\" + 0.007*\"health\" + 0.007*\"the\" + 0.007*\"for\" + 0.006*\"of\" + 0.005*\"mental\" + 0.005*\"on\" + 0.005*\"david\" + 0.005*\"in\" + 0.004*\"social\"\n",
            "\n",
            "Score: 0.14901325106620789\t \n",
            "Topic: 0.014*\"donald\" + 0.012*\"in\" + 0.009*\"after\" + 0.008*\"crash\" + 0.007*\"trump\" + 0.007*\"car\" + 0.005*\"dies\" + 0.005*\"on\" + 0.005*\"at\" + 0.005*\"man\"\n",
            "\n",
            "Score: 0.012509550899267197\t \n",
            "Topic: 0.022*\"coronavirus\" + 0.010*\"covid\" + 0.010*\"cases\" + 0.008*\"to\" + 0.007*\"vaccine\" + 0.006*\"of\" + 0.006*\"the\" + 0.005*\"new\" + 0.005*\"for\" + 0.005*\"in\"\n",
            "\n",
            "Score: 0.012509046122431755\t \n",
            "Topic: 0.017*\"news\" + 0.010*\"the\" + 0.008*\"lockdown\" + 0.007*\"rural\" + 0.007*\"markets\" + 0.006*\"to\" + 0.006*\"market\" + 0.006*\"abc\" + 0.006*\"national\" + 0.006*\"with\"\n",
            "\n",
            "Score: 0.012508787214756012\t \n",
            "Topic: 0.009*\"why\" + 0.008*\"to\" + 0.007*\"john\" + 0.007*\"thursday\" + 0.006*\"in\" + 0.006*\"the\" + 0.005*\"of\" + 0.005*\"fire\" + 0.005*\"for\" + 0.004*\"stories\"\n",
            "\n",
            "Score: 0.012508518993854523\t \n",
            "Topic: 0.019*\"19\" + 0.016*\"covid\" + 0.011*\"in\" + 0.008*\"us\" + 0.007*\"trump\" + 0.007*\"of\" + 0.006*\"to\" + 0.005*\"wall\" + 0.005*\"china\" + 0.005*\"the\"\n",
            "\n",
            "Score: 0.012508324347436428\t \n",
            "Topic: 0.012*\"the\" + 0.010*\"what\" + 0.008*\"to\" + 0.007*\"australia\" + 0.007*\"in\" + 0.006*\"of\" + 0.006*\"a\" + 0.006*\"afl\" + 0.006*\"day\" + 0.005*\"for\"\n",
            "\n",
            "Score: 0.012508139945566654\t \n",
            "Topic: 0.013*\"man\" + 0.012*\"police\" + 0.010*\"over\" + 0.010*\"of\" + 0.010*\"murder\" + 0.009*\"court\" + 0.009*\"charged\" + 0.008*\"in\" + 0.007*\"with\" + 0.006*\"interview\"\n",
            "\n",
            "Score: 0.012507958337664604\t \n",
            "Topic: 0.012*\"the\" + 0.009*\"country\" + 0.009*\"morrison\" + 0.009*\"drum\" + 0.008*\"in\" + 0.006*\"monday\" + 0.006*\"tuesday\" + 0.006*\"hour\" + 0.006*\"of\" + 0.005*\"queensland\"\n"
          ]
        }
      ]
    }
  ]
}